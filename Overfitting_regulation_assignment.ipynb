{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "hprice = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              saleprice   R-squared:                       0.773\n",
      "Model:                            OLS   Adj. R-squared:                  0.772\n",
      "Method:                 Least Squares   F-statistic:                     704.9\n",
      "Date:                Wed, 20 Nov 2019   Prob (F-statistic):               0.00\n",
      "Time:                        17:31:35   Log-Likelihood:                -17463.\n",
      "No. Observations:                1460   AIC:                         3.494e+04\n",
      "Df Residuals:                    1452   BIC:                         3.498e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const       -2.113e+04   1.91e+04     -1.104      0.270   -5.87e+04    1.64e+04\n",
      "overallqual  1.064e+04   1880.924      5.656      0.000    6949.495    1.43e+04\n",
      "grlivarea      15.4734      3.924      3.943      0.000       7.776      23.171\n",
      "garagecars   1.807e+04   2986.096      6.051      0.000    1.22e+04    2.39e+04\n",
      "garagearea      5.3775     10.343      0.520      0.603     -14.912      25.667\n",
      "totalsf        -5.3556      5.305     -1.010      0.313     -15.762       5.051\n",
      "int_over_sf     5.1266      0.623      8.224      0.000       3.904       6.349\n",
      "Pave         8861.2016   1.56e+04      0.566      0.571   -2.18e+04    3.96e+04\n",
      "==============================================================================\n",
      "Omnibus:                     1117.048   Durbin-Watson:                   1.990\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           194741.724\n",
      "Skew:                          -2.655   Prob(JB):                         0.00\n",
      "Kurtosis:                      59.330   Cond. No.                     4.46e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.46e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "hprice = pd.concat([hprice,pd.get_dummies(hprice.street, drop_first=True)], axis=1)\n",
    "dummy_columns = list(pd.get_dummies(hprice.street, drop_first=True).columns)\n",
    "\n",
    "hprice['totalsf'] = hprice['totalbsmtsf'] + hprice['firstflrsf'] + hprice['secondflrsf']\n",
    "hprice['int_over_sf'] = hprice['totalsf'] * hprice['overallqual']\n",
    "\n",
    "X = hprice[['overallqual', 'grlivarea', 'garagecars', 'garagearea', 'totalsf', 'int_over_sf'] + dummy_columns]\n",
    "Y = hprice['saleprice']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared and the adjusted R-squared of the model are 0.773 and 0.772 respectively. Hence, according to the R-squared, around 22.8% of the variance in the target variable is unexplained by the model. AIC and BIC scores are 34940 and 34980 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in training set is 1168\n",
      "The number of observations in test set is 292\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 465)\n",
    "\n",
    "print(\"The number of observations in training set is {}\".format(X_train.shape[0]))\n",
    "print(\"The number of observations in test set is {}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model in the training set is: 0.7640233922522901\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in the test set is: 0.7931114118523199\n",
      "Mean absolute error of the prediction is: 24698.238598022544\n",
      "Mean squared error of the prediction is: 1388988758.16082\n",
      "Root mean squared error of the prediction is: 37269.13948779633\n",
      "Mean absolute percentage error of the prediction is: 15.094458323173965\n"
     ]
    }
   ],
   "source": [
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lrm.predict(X_train)\n",
    "y_preds_test = lrm.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model in the training set is: {}\".format(lrm.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in the test set is: {}\".format(lrm.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 10.0\n",
      "R-squared of the model on the training set is: 0.7640193164122014\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.7933648570959095\n",
      "Mean absolute error of the prediction is: 24681.002964869473\n",
      "Mean squared error of the prediction is: 1387287201.795111\n",
      "Root mean squared error of the prediction is: 37246.304538774195\n",
      "Mean absolute percentage error of the prediction is: 15.07294353064981\n"
     ]
    }
   ],
   "source": [
    "alphas = [np.power(10.0,p) for p in np.arange(-10,40,1)]\n",
    "\n",
    "lassoregr = LassoCV(alphas=alphas) \n",
    "lassoregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lassoregr.predict(X_train)\n",
    "y_preds_test = lassoregr.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lassoregr.alpha_))\n",
    "print(\"R-squared of the model on the training set is: {}\".format(lassoregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(lassoregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 10.0\n",
      "R-squared of the model on the training set is: 0.7500467061909435\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.8175580007939539\n",
      "Mean absolute error of the prediction is: 22654.346699015332\n",
      "Mean squared error of the prediction is: 1224861594.2639413\n",
      "Root mean squared error of the prediction is: 34998.02271934718\n",
      "Mean absolute percentage error of the prediction is: 13.517278152484982\n"
     ]
    }
   ],
   "source": [
    "ridgeregr = RidgeCV(alphas=alphas) \n",
    "ridgeregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = ridgeregr.predict(X_train)\n",
    "y_preds_test = ridgeregr.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lassoregr.alpha_))\n",
    "print(\"R-squared of the model on the training set is: {}\".format(ridgeregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(ridgeregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 10.0\n",
      "R-squared of the model on the training set is: 0.7538899894760976\n",
      "-----Test set statistics-----\n",
      "R-squared of the model on the test set is: 0.8144634315146178\n",
      "Mean absolute error of the prediction is: 22882.737890213673\n",
      "Mean squared error of the prediction is: 1245637616.6575954\n",
      "Root mean squared error of the prediction is: 35293.59172226022\n",
      "Mean absolute percentage error of the prediction is: 13.674967132791188\n"
     ]
    }
   ],
   "source": [
    "elasticregr = ElasticNetCV(alphas=alphas) \n",
    "elasticregr.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = elasticregr.predict(X_train)\n",
    "y_preds_test = elasticregr.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lassoregr.alpha_))\n",
    "print(\"R-squared of the model on the training set is: {}\".format(elasticregr.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model on the test set is: {}\".format(elasticregr.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results Ridge regression and ElasticNet regression have the better results. Test set statistics in Ridge regression have the smaller values that means its model is the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
